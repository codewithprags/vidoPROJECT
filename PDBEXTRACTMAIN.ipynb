{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f6f36b",
   "metadata": {},
   "source": [
    "This jyupter note book is for running the defined funcions in pdbdownload\n",
    "\n",
    "Goal is to extract pdb files based on a selection of ID from a csv\n",
    "subset the csv for the selected ID and remove the ids that have multiple antigen chains separated by  | .\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5287cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import PDB\n",
    "from Bio.PDB import PDBParser, PDBIO\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b3ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdbdownload as pdbdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a380571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pdb Hchain Lchain  model antigen_chain antigen_type antigen_het_name  \\\n",
      "0  9fys      B      C      0             X      protein              NaN   \n",
      "1  9fys      I      M      0             Z      protein              NaN   \n",
      "2  9fyt      I      M      0             B      protein              NaN   \n",
      "3  9fyt      C      D      0             A      protein              NaN   \n",
      "4  9uxd      D      E      0             A      protein              NaN   \n",
      "\n",
      "         antigen_name                 short_header       date  ...   scfv  \\\n",
      "0  alpha-bungarotoxin                        TOXIN  7/16/2025  ...  False   \n",
      "1  alpha-bungarotoxin                        TOXIN  7/16/2025  ...  False   \n",
      "2    alpha-cobratoxin                        TOXIN  7/16/2025  ...  False   \n",
      "3    alpha-cobratoxin                        TOXIN  7/16/2025  ...  False   \n",
      "4  spike glycoprotein  VIRAL PROTEIN/IMMUNE SYSTEM  7/16/2025  ...  False   \n",
      "\n",
      "  engineered heavy_subclass light_subclass light_ctype affinity delta_g  \\\n",
      "0       True          IGHV1          IGLV6      Lambda      NaN     NaN   \n",
      "1       True          IGHV1          IGLV6      Lambda      NaN     NaN   \n",
      "2       True          IGHV1          IGLV3      Lambda      NaN     NaN   \n",
      "3       True          IGHV1          IGLV3      Lambda      NaN     NaN   \n",
      "4       True          IGHV3          IGKV3       Kappa      NaN     NaN   \n",
      "\n",
      "  affinity_method temperature pmid  \n",
      "0             NaN         NaN  NaN  \n",
      "1             NaN         NaN  NaN  \n",
      "2             NaN         NaN  NaN  \n",
      "3             NaN         NaN  NaN  \n",
      "4             NaN         NaN  NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "Number of rows in main_csv: 6483\n"
     ]
    }
   ],
   "source": [
    "main_csv = pd.read_csv(\"HOMOE_Ab_An_summary.csv\")\n",
    "\n",
    "print(main_csv.head())\n",
    "\n",
    "print(\"Number of rows in main_csv:\", main_csv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff4b8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdbdownload as pdbdl\n",
    "#subset the PDB ID for first 2000\n",
    "subset_df = pdbdl.subset_pdb_ids(\"HOMOE_Ab_An_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f661b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 2000\n",
      "After removing NaN values: 1919\n",
      "After removing rows with '|' in antigen_chain: 0\n",
      "After keeping first occurrence of each PDB: 0\n",
      "Saved 0 unique PDB entries to filtered_pdb_ids.csv\n"
     ]
    }
   ],
   "source": [
    "filtered_df = pdbdl.filter_pdb_ids(\"subset_pdb_ids.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ee9e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset file has 2000 rows\n",
      "Columns: ['pdb', 'Hchain', 'Lchain', 'model', 'antigen_chain', 'antigen_type', 'antigen_het_name', 'antigen_name', 'short_header', 'date', 'compound', 'organism', 'heavy_species', 'light_species', 'antigen_species', 'authors', 'resolution', 'method', 'r_free', 'r_factor', 'scfv', 'engineered', 'heavy_subclass', 'light_subclass', 'light_ctype', 'affinity', 'delta_g', 'affinity_method', 'temperature', 'pmid']\n",
      "\n",
      "First few rows:\n",
      "    pdb Hchain Lchain  model antigen_chain antigen_type antigen_het_name  \\\n",
      "0  9fys      B      C      0             X      protein              NaN   \n",
      "1  9fys      I      M      0             Z      protein              NaN   \n",
      "2  9fyt      I      M      0             B      protein              NaN   \n",
      "3  9fyt      C      D      0             A      protein              NaN   \n",
      "4  9uxd      D      E      0             A      protein              NaN   \n",
      "\n",
      "         antigen_name                 short_header       date  ...   scfv  \\\n",
      "0  alpha-bungarotoxin                        TOXIN  7/16/2025  ...  False   \n",
      "1  alpha-bungarotoxin                        TOXIN  7/16/2025  ...  False   \n",
      "2    alpha-cobratoxin                        TOXIN  7/16/2025  ...  False   \n",
      "3    alpha-cobratoxin                        TOXIN  7/16/2025  ...  False   \n",
      "4  spike glycoprotein  VIRAL PROTEIN/IMMUNE SYSTEM  7/16/2025  ...  False   \n",
      "\n",
      "  engineered heavy_subclass light_subclass light_ctype affinity  delta_g  \\\n",
      "0       True          IGHV1          IGLV6      Lambda      NaN      NaN   \n",
      "1       True          IGHV1          IGLV6      Lambda      NaN      NaN   \n",
      "2       True          IGHV1          IGLV3      Lambda      NaN      NaN   \n",
      "3       True          IGHV1          IGLV3      Lambda      NaN      NaN   \n",
      "4       True          IGHV3          IGKV3       Kappa      NaN      NaN   \n",
      "\n",
      "  affinity_method  temperature  pmid  \n",
      "0             NaN          NaN   NaN  \n",
      "1             NaN          NaN   NaN  \n",
      "2             NaN          NaN   NaN  \n",
      "3             NaN          NaN   NaN  \n",
      "4             NaN          NaN   NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Missing values:\n",
      "pdb: 0\n",
      "antigen_chain: 13\n",
      "Hchain: 6\n",
      "Lchain: 68\n",
      "\n",
      "Rows after removing NaN: 1919\n",
      "Rows with '|' in antigen_chain: 1919\n",
      "Rows without '|' in antigen_chain: 0\n",
      "\n",
      "Sample antigen_chain values:\n",
      "['X', 'Z', 'B', 'A', 'A', 'B', 'C', 'A', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "# Debug: Let's check what's in the subset file and why filtering results in empty CSV\n",
    "import pandas as pd\n",
    "\n",
    "# Load the subset file to see what we're working with\n",
    "subset_df = pd.read_csv(\"subset_pdb_ids.csv\")\n",
    "print(f\"Subset file has {len(subset_df)} rows\")\n",
    "print(f\"Columns: {list(subset_df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(subset_df.head())\n",
    "\n",
    "# Check for missing values in key columns\n",
    "print(f\"\\nMissing values:\")\n",
    "print(f\"pdb: {subset_df['pdb'].isna().sum()}\")\n",
    "print(f\"antigen_chain: {subset_df['antigen_chain'].isna().sum()}\")\n",
    "print(f\"Hchain: {subset_df['Hchain'].isna().sum()}\")\n",
    "print(f\"Lchain: {subset_df['Lchain'].isna().sum()}\")\n",
    "\n",
    "# Check how many rows would remain after dropna\n",
    "after_dropna = subset_df.dropna(subset=['pdb', 'antigen_chain', 'Hchain', 'Lchain'])\n",
    "print(f\"\\nRows after removing NaN: {len(after_dropna)}\")\n",
    "\n",
    "# Check how many have \"|\" in antigen_chain\n",
    "if len(after_dropna) > 0:\n",
    "    has_pipe = after_dropna['antigen_chain'].str.contains('|', na=False).sum()\n",
    "    print(f\"Rows with '|' in antigen_chain: {has_pipe}\")\n",
    "    print(f\"Rows without '|' in antigen_chain: {len(after_dropna) - has_pipe}\")\n",
    "    \n",
    "    # Show some examples of antigen_chain values\n",
    "    print(f\"\\nSample antigen_chain values:\")\n",
    "    print(after_dropna['antigen_chain'].head(10).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff3cc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing pipe detection methods:\n",
      "Method 1 - str.contains('|'): 1919\n",
      "Method 2 - str.contains('\\|'): 363\n",
      "Method 3 - str.contains('|', regex=False): 363\n",
      "\n",
      "Rows that actually contain '|': 363\n",
      "Examples with '|':\n",
      "26    B | A\n",
      "31    C | D\n",
      "36    B | A\n",
      "43    B | A\n",
      "67    A | B\n",
      "Name: antigen_chain, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Test the pipe character detection\n",
    "after_dropna = subset_df.dropna(subset=['pdb', 'antigen_chain', 'Hchain', 'Lchain'])\n",
    "\n",
    "# Test different ways to detect \"|\"\n",
    "print(\"Testing pipe detection methods:\")\n",
    "print(f\"Method 1 - str.contains('|'): {after_dropna['antigen_chain'].str.contains('|', na=False).sum()}\")\n",
    "print(f\"Method 2 - str.contains('\\\\|'): {after_dropna['antigen_chain'].str.contains('\\\\|', na=False).sum()}\")\n",
    "print(f\"Method 3 - str.contains('|', regex=False): {after_dropna['antigen_chain'].str.contains('|', regex=False, na=False).sum()}\")\n",
    "\n",
    "# Check if any antigen_chain actually contains \"|\"\n",
    "actual_pipes = after_dropna[after_dropna['antigen_chain'].str.contains('\\\\|', na=False)]\n",
    "print(f\"\\nRows that actually contain '|': {len(actual_pipes)}\")\n",
    "\n",
    "if len(actual_pipes) > 0:\n",
    "    print(\"Examples with '|':\")\n",
    "    print(actual_pipes['antigen_chain'].head())\n",
    "else:\n",
    "    print(\"No rows actually contain '|' character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d79d22d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 2000\n",
      "After removing NaN values: 1919\n",
      "After removing rows with '|' in antigen_chain: 1556\n",
      "After keeping first occurrence of each PDB: 698\n",
      "Saved 698 unique PDB entries to filtered_pdb_ids.csv\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed filtering function\n",
    "import importlib\n",
    "importlib.reload(pdbdl)  # Reload the module to get the updated function\n",
    "\n",
    "filtered_df = pdbdl.filter_pdb_ids(\"subset_pdb_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641309ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 698 filtered PDB entries\n",
      "Will download 698 PDB files\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m save_directory = \u001b[33m\"\u001b[39m\u001b[33mD:/VIDO/VIDO PROJECT FILES/PDB_legacy_files\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#download the PDB legacy files for the selected PDB ids\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mpdbdl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_pdb_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\VIDO\\VIDO PROJECT FILES\\pdbdownload.py:44\u001b[39m, in \u001b[36mdownload_pdb_files\u001b[39m\u001b[34m(pdb_ids, save_directory)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pdb_id \u001b[38;5;129;01min\u001b[39;00m pdb_ids:\n\u001b[32m     43\u001b[39m     url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://files.rcsb.org/download/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdb_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pdb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     response = \u001b[43mrequests\u001b[49m.get(url)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdb_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pdb\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# Reload the module after installing requests\n",
    "import importlib\n",
    "import pdbdownload as pdbdl\n",
    "importlib.reload(pdbdl)\n",
    "\n",
    "# Load the filtered CSV file as a DataFrame\n",
    "filtered_df = pd.read_csv(\"filtered_pdb_ids.csv\")\n",
    "print(f\"Loaded {len(filtered_df)} filtered PDB entries\")\n",
    "\n",
    "# Extract PDB IDs and set up download\n",
    "pdb_ids = filtered_df['pdb'].tolist()\n",
    "print(f\"Will download {len(pdb_ids)} PDB files\")\n",
    "\n",
    "save_directory = \"D:/VIDO/VIDO PROJECT FILES/PDB_legacy_files\"\n",
    "\n",
    "#download the PDB legacy files for the selected PDB ids\n",
    "pdbdl.download_pdb_files(pdb_ids, save_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
